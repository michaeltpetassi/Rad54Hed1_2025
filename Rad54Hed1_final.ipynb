{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be0fae-1417-4780-86fa-989255ed1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for reads with both desired flanking sequence from input .fastq; counts and exports counts to a .csv output\n",
    "#Also exports a report .txt file with information on how many reads match each flanking sequence for troubleshooting\n",
    "\n",
    "import csv\n",
    "\n",
    "def count_mismatches(sequence, target):\n",
    "    \"\"\"Count the number of mismatches between a sequence and a target sequence.\"\"\"\n",
    "    mismatches = sum(1 for a, b in zip(sequence, target) if a != b)\n",
    "    return mismatches + abs(len(sequence) - len(target))\n",
    "\n",
    "def find_sequences_in_reads(upstream_seq, downstream_seq, fastq_file):\n",
    "    sequences = {}\n",
    "    reads_with_flanking = 0\n",
    "    reads_without_flanking = 0\n",
    "    reads_with_only_upstream = 0\n",
    "    reads_with_only_downstream = 0\n",
    "    mismatches_upstream = {}\n",
    "    mismatches_downstream = {}\n",
    "    length_distribution = {}\n",
    "\n",
    "    with open(fastq_file, 'r') as f:\n",
    "        while True:\n",
    "            # Read four lines at a time (ID, sequence, \"+\", quality)\n",
    "            read_id = f.readline().strip()\n",
    "            sequence = f.readline().strip()\n",
    "            _ = f.readline()  # Skip the third line (\"+\")\n",
    "            _ = f.readline()  # Skip the quality scores line\n",
    "            \n",
    "            # Check if we've reached the end of the file\n",
    "            if not read_id:\n",
    "                break\n",
    "            \n",
    "            # Find upstream and downstream sequences\n",
    "            upstream_index = sequence.find(upstream_seq)\n",
    "            downstream_index = sequence.find(downstream_seq)\n",
    "            \n",
    "            # If both sequences are found, extract the sequence between them\n",
    "            if upstream_index != -1 and downstream_index != -1:\n",
    "                reads_with_flanking += 1\n",
    "                start_index = upstream_index + len(upstream_seq)\n",
    "                end_index = downstream_index\n",
    "                extracted_sequence = sequence[start_index:end_index]\n",
    "                extracted_length = len(extracted_sequence)\n",
    "                \n",
    "                # Update the count for the extracted sequence\n",
    "                if extracted_sequence in sequences:\n",
    "                    sequences[extracted_sequence] += 1\n",
    "                else:\n",
    "                    sequences[extracted_sequence] = 1\n",
    "                \n",
    "                # Update the length distribution\n",
    "                if extracted_length in length_distribution:\n",
    "                    length_distribution[extracted_length] += 1\n",
    "                else:\n",
    "                    length_distribution[extracted_length] = 1\n",
    "            else:\n",
    "                reads_without_flanking += 1\n",
    "                if upstream_index != -1:\n",
    "                    reads_with_only_upstream += 1\n",
    "                if downstream_index != -1:\n",
    "                    reads_with_only_downstream += 1\n",
    "\n",
    "                # Count mismatches for upstream and downstream sequences separately\n",
    "                if upstream_seq not in sequence:\n",
    "                    mismatches_up = count_mismatches(sequence[:len(upstream_seq)], upstream_seq)\n",
    "                    mismatches_upstream[mismatches_up] = mismatches_upstream.get(mismatches_up, 0) + 1\n",
    "\n",
    "                if downstream_seq not in sequence:\n",
    "                    mismatches_down = count_mismatches(sequence[-len(downstream_seq):], downstream_seq)\n",
    "                    mismatches_downstream[mismatches_down] = mismatches_downstream.get(mismatches_down, 0) + 1\n",
    "    \n",
    "    return (sequences, reads_with_flanking, reads_without_flanking, \n",
    "            reads_with_only_upstream, reads_with_only_downstream, \n",
    "            mismatches_upstream, mismatches_downstream, length_distribution)\n",
    "\n",
    "def export_counts_to_csv(sequences_count, output_csv_file):\n",
    "    with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([\"Sequence\", \"Count\"])\n",
    "        for sequence, count in sequences_count.items():\n",
    "            csvwriter.writerow([sequence, count])\n",
    "\n",
    "def write_report(reads_with_flanking, reads_without_flanking, reads_with_only_upstream, reads_with_only_downstream, mismatches_upstream, mismatches_downstream, length_distribution, output_report_file):\n",
    "    with open(output_report_file, 'w') as reportfile:\n",
    "        reportfile.write(f\"Reads with flanking sequences: {reads_with_flanking}\\n\")\n",
    "        reportfile.write(f\"Reads without flanking sequences: {reads_without_flanking}\\n\")\n",
    "        reportfile.write(f\"Reads with only upstream sequence: {reads_with_only_upstream}\\n\")\n",
    "        reportfile.write(f\"Reads with only downstream sequence: {reads_with_only_downstream}\\n\")\n",
    "        \n",
    "        reportfile.write(\"Mismatches for upstream sequence:\\n\")\n",
    "        for mismatches, count in sorted(mismatches_upstream.items()):\n",
    "            reportfile.write(f\"  {mismatches} mismatches: {count} reads\\n\")\n",
    "        \n",
    "        reportfile.write(\"Mismatches for downstream sequence:\\n\")\n",
    "        for mismatches, count in sorted(mismatches_downstream.items()):\n",
    "            reportfile.write(f\"  {mismatches} mismatches: {count} reads\\n\")\n",
    "\n",
    "        reportfile.write(\"Length distribution of sequences between flanking sequences:\\n\")\n",
    "        for length, count in sorted(length_distribution.items()):\n",
    "            reportfile.write(f\"  Length {length}: {count} sequences\\n\")\n",
    "\n",
    "# Example usage:\n",
    "upstream_sequence = \"GGTTGGCCAAGGATCCGACA\"\n",
    "downstream_sequence = \"CATATCCAGTACACTTTGAG\"\n",
    "fastq_file = \"E106.fastq\"\n",
    "output_csv_file = \"E106.csv\"\n",
    "output_report_file = \"E106_report.txt\"\n",
    "\n",
    "(sequences_count, reads_with_flanking, reads_without_flanking, \n",
    " reads_with_only_upstream, reads_with_only_downstream, \n",
    " mismatches_upstream, mismatches_downstream, length_distribution) = find_sequences_in_reads(upstream_sequence, downstream_sequence, fastq_file)\n",
    "\n",
    "# Export the count for each extracted sequence to a CSV file\n",
    "export_counts_to_csv(sequences_count, output_csv_file)\n",
    "\n",
    "# Write the report to a text file\n",
    "write_report(reads_with_flanking, reads_without_flanking, reads_with_only_upstream, reads_with_only_downstream, mismatches_upstream, mismatches_downstream, length_distribution, output_report_file)\n",
    "\n",
    "# Print the count for each extracted sequence (for verification)\n",
    "#for sequence, count in sequences_count.items():\n",
    "#    print(f\"Sequence: {sequence}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348727ef-ddac-403c-8596-631524364808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filters position of interest sequences to a desired # nt and translate to amino acid sequence\n",
    "\n",
    "import csv\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def translate_sequences(input_csv_file, nt_length, output_csv_file):\n",
    "    translated_sequences = {}\n",
    "\n",
    "    # Read the input CSV file\n",
    "    with open(input_csv_file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        header = next(csvreader)  # Skip header\n",
    "\n",
    "        for row in csvreader:\n",
    "            sequence = row[0]\n",
    "            count = int(row[1])\n",
    "\n",
    "            # Filter sequences by the given nucleotide length\n",
    "            if len(sequence) == nt_length:\n",
    "                dna_seq = Seq(sequence)\n",
    "                aa_seq = str(dna_seq.translate())\n",
    "\n",
    "                # Update the count for the translated sequence\n",
    "                if aa_seq in translated_sequences:\n",
    "                    translated_sequences[aa_seq] += count\n",
    "                else:\n",
    "                    translated_sequences[aa_seq] = count\n",
    "\n",
    "    # Write the translated sequences and counts to the output CSV file\n",
    "    with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([\"Amino Acid Sequence\", \"Count\"])\n",
    "        for aa_seq, count in translated_sequences.items():\n",
    "            csvwriter.writerow([aa_seq, count])\n",
    "\n",
    "# Example usage\n",
    "input_csv_file = \"E106.csv\"\n",
    "nt_length = 9  # Example nucleotide length to filter by\n",
    "output_csv_file = input_csv_file.replace(\".csv\", \"_AA.csv\")\n",
    "\n",
    "translate_sequences(input_csv_file, nt_length, output_csv_file)\n",
    "\n",
    "print(f\"Translated sequences have been saved to {output_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ab97b-3f1a-4bbf-9780-409b5b7ad164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligns data from two _AA.csv files to a single .csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "def compare_aa_counts(file1, file2, output_file):\n",
    "    # Read the first file into a dictionary\n",
    "    counts1 = {}\n",
    "    with open(file1, 'r') as csvfile1:\n",
    "        csvreader = csv.reader(csvfile1)\n",
    "        header1 = next(csvreader)  # Skip header\n",
    "        for row in csvreader:\n",
    "            aa_sequence = row[0]\n",
    "            count = int(row[1])\n",
    "            counts1[aa_sequence] = count\n",
    "\n",
    "    # Read the second file into a dictionary\n",
    "    counts2 = {}\n",
    "    with open(file2, 'r') as csvfile2:\n",
    "        csvreader = csv.reader(csvfile2)\n",
    "        header2 = next(csvreader)  # Skip header\n",
    "        for row in csvreader:\n",
    "            aa_sequence = row[0]\n",
    "            count = int(row[1])\n",
    "            counts2[aa_sequence] = count\n",
    "\n",
    "    # Combine the counts from both files\n",
    "    combined_counts = {}\n",
    "    for aa_sequence in set(counts1.keys()).union(set(counts2.keys())):\n",
    "        combined_counts[aa_sequence] = [counts1.get(aa_sequence, 0), counts2.get(aa_sequence, 0)]\n",
    "\n",
    "    # Write the combined counts to the output CSV file\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([\"Amino Acid Sequence\", \"Count in File 1\", \"Count in File 2\"])\n",
    "        for aa_sequence, counts in combined_counts.items():\n",
    "            csvwriter.writerow([aa_sequence, counts[0], counts[1]])\n",
    "\n",
    "# Example usage\n",
    "file1 = \"E105_AA.csv\"\n",
    "file2 = \"E106_AA.csv\"\n",
    "output_file = \"E105_E106.csv\"\n",
    "\n",
    "compare_aa_counts(file1, file2, output_file)\n",
    "\n",
    "print(f\"Comparison of amino acid sequences has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6701d1c-edcd-4715-a451-c1feb5ad77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates raw fold-enrichment values and converts .csv to .xlxs\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# Function to process a single CSV file and convert it to XLSX\n",
    "def process_file(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Remove rows where 'Amino Acid Sequence' contains 'X'\n",
    "    df = df[~df['Amino Acid Sequence'].str.contains('X')]\n",
    "\n",
    "    # Calculate totals for 'Count in File 1' (column 2) and 'Count in File 2' (column 3)\n",
    "    total_file1 = df['Count in File 1'].sum()\n",
    "    total_file2 = df['Count in File 2'].sum()\n",
    "\n",
    "    # Add the Fold-enrichment column\n",
    "    df['Fold-enrichment'] = (df['Count in File 2'] / total_file2) / (df['Count in File 1'] / total_file1)\n",
    "\n",
    "    # Create ExcelWriter object and write DataFrame to Excel\n",
    "    output_file = file_path.replace('.csv', '.xlsx')\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "        # Access the workbook and the worksheet\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "        # Highlight rows where 'Count in File 1' < 100 (column B is 'Count in File 1')\n",
    "        yellow_fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "        for row in range(2, len(df) + 2):  # Start from row 2 (Excel is 1-indexed)\n",
    "            cell_value = worksheet.cell(row=row, column=2).value\n",
    "            if cell_value < 100:\n",
    "                for col in range(1, 5):  # Apply fill to columns A, B, C, and D\n",
    "                    worksheet.cell(row=row, column=col).fill = yellow_fill\n",
    "\n",
    "    print(f\"Processed {file_path} -> {output_file}\")\n",
    "\n",
    "# Function to process all CSV files in a directory\n",
    "def process_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            process_file(file_path)\n",
    "\n",
    "# Example usage\n",
    "directory = r\"/path/to/directory\"  # Replace with your directory path\n",
    "process_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5628681-c061-4039-a76b-fa39896997a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to sort single-mutant data for each position, can be used to sort out any given sequence,\n",
    "\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "def sort_amino_acid_sequences(input_file, output_file, position_criteria):\n",
    "    # Read the .xlsx file into a pandas DataFrame\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Extract the sequence length from the first sequence (assumes all sequences have the same length)\n",
    "    seq_length = len(df[\"Amino Acid Sequence\"].iloc[0])\n",
    "\n",
    "    # Ensure position_criteria matches the sequence length\n",
    "    if len(position_criteria) != seq_length:\n",
    "        raise ValueError(f\"Position criteria length ({len(position_criteria)}) does not match sequence length ({seq_length}).\")\n",
    "\n",
    "    # Generate a regular expression based on position criteria\n",
    "    regex_pattern = ''\n",
    "    for i, criteria in enumerate(position_criteria):\n",
    "        if criteria == 'x':\n",
    "            regex_pattern += '.'  # Match any character\n",
    "        else:\n",
    "            regex_pattern += criteria  # Match the specified amino acid\n",
    "\n",
    "    # Filter the DataFrame for sequences matching the pattern\n",
    "    sorted_df = df[df[\"Amino Acid Sequence\"].str.contains(regex_pattern)]\n",
    "    unsorted_df = df[~df[\"Amino Acid Sequence\"].str.contains(regex_pattern)]\n",
    "\n",
    "    # Combine the sorted and unsorted DataFrames, adding a blank row in between\n",
    "    combined_df = pd.concat([sorted_df, pd.DataFrame([['']*len(df.columns)], columns=df.columns), unsorted_df])\n",
    "\n",
    "    # Write the combined data to the output file (temp)\n",
    "    combined_df.to_excel(output_file, index=False)\n",
    "\n",
    "    # Now, open the file again using openpyxl to apply highlighting\n",
    "    wb = openpyxl.load_workbook(output_file)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Yellow fill style for highlighting\n",
    "    yellow_fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "\n",
    "    # Iterate over the rows and check values in column 2 for highlighting\n",
    "    for row in range(2, ws.max_row + 1):  # Start from row 2 to skip header\n",
    "        count_in_file1 = ws.cell(row=row, column=2).value\n",
    "        if count_in_file1 is not None and count_in_file1 < 100:\n",
    "            for col in range(1, ws.max_column + 1):\n",
    "                ws.cell(row=row, column=col).fill = yellow_fill\n",
    "\n",
    "    # Save the workbook with the highlighting\n",
    "    wb.save(output_file)\n",
    "    print(f\"Sorted data with highlighting saved to {output_file}\")\n",
    "\n",
    "# Specify input and output file paths\n",
    "input_file = r'E105_E106.xlsx'\n",
    "output_file = r'E105_E106_P21.xlsx'\n",
    "\n",
    "# Set the position criteria (for example: 'K' for position 1, 'x' for position 2, 'G' for position 3 in a 3-residue sequence)\n",
    "# For 4-residue sequences, add a 4th position if necessary\n",
    "position_criteria = ['R', 'L', 'x']  # Modify this as needed\n",
    "\n",
    "# Run the function to sort amino acid sequences and highlight rows\n",
    "sort_amino_acid_sequences(input_file, output_file, position_criteria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a56d22-4064-47c3-83a1-eaab939e63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes all .xlxs in a given directory with reads before, reads after, fold-enrichment and adds Log2 and Log10 columns\n",
    "#Demands 100 reads in the before pool; if >100 reads in before pool and 0 reads in after pool, fold-enrichment is calculated as if there was 1\n",
    "#read in the output-i.e. approximate resolution limit of the sequencing.\n",
    "\n",
    "import os\n",
    "import math\n",
    "import openpyxl\n",
    "\n",
    "def fix_and_add_log_columns_to_excel(directory):\n",
    "    # Traverse all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            print(f\"Processing file: {filename}\")\n",
    "\n",
    "            # Load the workbook and select the active sheet\n",
    "            workbook = openpyxl.load_workbook(file_path)\n",
    "            sheet = workbook.active\n",
    "\n",
    "            # Add headers for new columns if not already present\n",
    "            sheet.cell(row=1, column=5, value=\"Log2(fold-enrichment)\")\n",
    "            sheet.cell(row=1, column=6, value=\"Log10(fold-enrichment)\")\n",
    "\n",
    "            # Iterate through the rows, assuming data starts from row 2 (row 1 is the header)\n",
    "            for row in range(2, sheet.max_row + 1):\n",
    "                try:\n",
    "                    # Get the values in columns 2, 3, and 4\n",
    "                    value_in_column_2 = sheet.cell(row=row, column=2).value\n",
    "                    value_in_column_3 = sheet.cell(row=row, column=3).value\n",
    "                    fold_enrichment = sheet.cell(row=row, column=4).value\n",
    "\n",
    "                    if value_in_column_2 >= 100:\n",
    "                        # If column 4 is 0 and column 3 is 0, update column 4\n",
    "                        if fold_enrichment == 0 and value_in_column_3 == 0:\n",
    "                            fold_enrichment = 1 / value_in_column_2\n",
    "                            sheet.cell(row=row, column=4, value=fold_enrichment)\n",
    "\n",
    "                        # Calculate log2 and log10 of column 4\n",
    "                        if fold_enrichment > 0:\n",
    "                            log2_value = math.log2(fold_enrichment)\n",
    "                            log10_value = math.log10(fold_enrichment)\n",
    "                        else:\n",
    "                            log2_value = log10_value = None  # Handle cases where fold-enrichment is non-positive\n",
    "\n",
    "                        # Write the values to columns 5 and 6\n",
    "                        sheet.cell(row=row, column=5, value=log2_value)\n",
    "                        sheet.cell(row=row, column=6, value=log10_value)\n",
    "                    else:\n",
    "                        # If column 2 is less than 100, leave columns 4, 5, and 6 blank\n",
    "                        sheet.cell(row=row, column=4, value=None)\n",
    "                        sheet.cell(row=row, column=5, value=None)\n",
    "                        sheet.cell(row=row, column=6, value=None)\n",
    "\n",
    "                except TypeError:\n",
    "                    # If there is invalid data in column 2, 3, or 4, skip the row\n",
    "                    print(f\"Skipping row {row} due to invalid data.\")\n",
    "\n",
    "            # Save the modified workbook\n",
    "            workbook.save(file_path)\n",
    "            print(f\"Updated file saved: {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory = r\"\"\n",
    "    fix_and_add_log_columns_to_excel(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68bf44-c401-4212-a6d2-5125640abb90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
